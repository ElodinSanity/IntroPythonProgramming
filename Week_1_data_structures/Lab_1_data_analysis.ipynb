{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Lab_1_data_analysis.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1: Introduction to manipulating data with numpy\n",
    "\n",
    "**Motivation**: Whether you're in engineering or business or health care - almost any field nowadays - you need to be able to work with data. Just about every thing that touches a computer now has the ability to store data. Most of this data will be numbers, but sometimes it will be qualitative data (think 3 people like this, 10 people don't).\n",
    "\n",
    "You can do a lot of data analysis with spreadsheets, but at some point it's almost always easier to write some code to either *put* data into a spreadsheet in a form that's useful, to *pull* specific data from one (or more) spreadsheets, or to automate some processes (like creating six custom plots from this month's data showing price trends). Being able to write a bit of code to clean up or re-purpose data is really useful, and not too difficult.\n",
    "\n",
    "- Lab week 1: Read in data, re-arrange it, and use it to do (text-based) statistical analysis\n",
    "- Lab week 2: Same thing again, but this time with functions so you can re-use code\n",
    "- Lab week 3: Plot the data you worked with in labs week 1 & 2\n",
    "- Homework weeks 1, 2 & 3: \n",
    "-- Make the code more general, so you can look at different data channels\n",
    "-- Make nicer plots\n",
    "\n",
    "Some notes on the data you'll be working with. This is real data captured by sensors on human hands engaged in hand-clapping game activities. Each hand has an accelerometer and a gyroscope. Each file contains a data stream from these sensors from a specific human subject (S1, S2, etc) engaged in a particular motion (F for \"high-five\", S for \"snap\", C for \"clap\"). For example, `S10F6.csv` is subject 10 performing a high-five for the 6th time.\n",
    "\n",
    "**Big picture: We want to know if someone is performing a high-five, snap, or clap based on this sensor data.** Each row of each CSV file is data from a single point in time. Each column is a data point from a sensor at this point in time. We want to plot/analyze data from different motions and see if there is a difference between them.\n",
    "\n",
    "For this lab the goal is to pull out one data channel from one subject (the right hand accelerometer) and print out statistics for different motions. Yes, you could do all of this by manually going into the spreadsheet and setting up some spreadsheet formulas. That works for one data channel... but what if you want to do a different one? Or the data file format changes because someone added another sensor? Or you're asked to throw out the biggest n samples?\n",
    "\n",
    "Yes, this is going to be frustrating/seem like a lot of work for nothing the first time you do it. The point is not\n",
    "to do this particular task, but to learn how to access data in dictionaries, lists, and numpy arrays to \"pull out\"\n",
    "data that you're interested in.\n",
    "\n",
    "Slides with further instructions/examples (open them now): https://docs.google.com/presentation/d/1lVYGqoStt0ZdnRAYMfF9Km6f0NgMNkuYgINsRhXASwI/edit?usp=sharing\n",
    "\n",
    "Note: Next week we'll take what we write here and put it into functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that we need to import - numpy and json (for loading the description file)\n",
    "import numpy as np\n",
    "import json as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "### Reading in data\n",
    "\n",
    "TODO First step, read in the data from **`Data/S01C01.csv`**, which contains sensor readings from subject 1 performing a _clap_, and put it in a numpy array `clap_data`. Don't forget to set the delimiter.\n",
    " - to find out more about the numpy method **`loadtxt`**, Google *numpy loadtxt* \n",
    " - there's also an example in **a_tutorial_numpy.ipynb**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO - put the code to load the data \n",
    "#  Make sure you save it into the variable name given - clap_data - or the autograder won't work.\n",
    "clap_data = np.loadtxt(fname=\"Data/S01C01.csv\", dtype=\"float\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "\n",
    "# This bit of code *builds* a data set of a similar form to the one you just read in, but with random data. \n",
    "#  5 time steps 13 channels \n",
    "#     (time, x,y,z, x,y,z, x,y,z, x,y,z ) \n",
    "#    the x,y,z is for RH accel, RH gyro, LH accel, LH gyro\n",
    "#  We'll use this data set to write more example code for the problems in the lab\n",
    "# Look in the slides and also open up Data/data_description.json for more information on this format\n",
    "\n",
    "# Make space\n",
    "my_test_data = np.zeros((5, 13))\n",
    "\n",
    "# First column: timestamp\n",
    "my_test_data[:, 0] = np.arange(0, my_test_data.shape[0])\n",
    "\n",
    "# x-data\n",
    "my_test_data[:, 1::3] = np.linspace(start=0, stop=1.0, num=4)\n",
    "\n",
    "# y-data\n",
    "my_test_data[:, 2::3] = np.random.uniform(-1.0, 0.0, size=(5, 4))\n",
    "\n",
    "# z-data\n",
    "my_test_data[:, 3::3] = np.random.uniform(10.0, 20.0, size=(5, 4))\n",
    "\n",
    "# Number of rows is in shape[0], columns in shape[1]\n",
    "num_rows = my_test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# - set the n_time_steps variable. Do NOT just put in a number - use the variable clap_data to calculate this.\n",
    "# - change the print line to print out the number of time steps\n",
    "\n",
    "n_time_steps = np.sum(len(clap_data[:, :-1:12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third column: [18.71127298 14.98189592 18.94563879 19.5607784  14.11723309]\n",
      "How many numbers are above 0.5? 5\n",
      "Sum of array as double 5.0 and integer 5\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE\n",
    "# Remember you want all of the rows - that's what the : is for\n",
    "# To get just the fourth column, use 3 (arrays are \"zero-indexed\", so the first column is 0)\n",
    "# To understand: Why is the fourth column the one with the z dimension of the rhs accel?\n",
    "get_third_column = my_test_data[:, 3]\n",
    "print(f\"Third column: {get_third_column}\")\n",
    "\n",
    "# An example of count_nonzero\n",
    "#  Make a numpy array with 10 elements going from zero to 1\n",
    "ten_numbers = np.linspace(0, 1, 10)\n",
    "# Count the number of Trues in the Boolean numpy array created by ten_numbers > 0.5\n",
    "print(f\"How many numbers are above 0.5? {np.count_nonzero(ten_numbers > 0.5)}\")\n",
    "\n",
    "# Sum will return a double, not an integer. Use int() to change a double to an integer\n",
    "#   You can tell it's a double by the 10.0 on the print out\n",
    "print(f\"Sum of array as double {np.sum(ten_numbers)} and integer {int(np.sum(ten_numbers))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints with positive z: 53\n",
      "Number of datapoints with negative z: 48\n"
     ]
    }
   ],
   "source": [
    "# TODO - set the variables n_pos_z and n_neg_z and print them out. Do NOT just put in a number - use the variable\n",
    "# clap_data.\n",
    "\n",
    "z_data = clap_data[:, 3] #getting all z co-ordinate data\n",
    "\n",
    "#bool arrays for pos/neg position\n",
    "zPos = z_data > 0\n",
    "zNeg = z_data < 0\n",
    "\n",
    "n_pos_z = np.sum(zPos)\n",
    "print(f\"Number of datapoints with positive z: {n_pos_z}\")\n",
    "\n",
    "n_neg_z = np.sum(zNeg)\n",
    "print(f\"Number of datapoints with negative z: {n_neg_z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>count_rows</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "count_rows results: All test cases passed!"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"count_rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "#### JSON, lists, and dictionaries: Getting information from a file\n",
    "The format of the spreadsheet data is given in `Data/data_description.json`.\n",
    "\n",
    "TODO: Open up the file using VSCode (just click on data then click on the file) and look through it to see if it makes sense. Also open up `S01C01.csv` the same way and make sure you understand the data format (see slides).\n",
    "\n",
    "- Step 1 (this problem): Figure out how to get the `\"data_channels\"` list out of `data_description`\n",
    "Note: **`data_description`** is a dictionary.\n",
    "\n",
    "- Step 2 (this problem): Find the size of the list\n",
    "\n",
    "- Step 3 (next problem): Find the total number of dimensions of the data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
=======
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
>>>>>>> 12de47a0ef9ec65719f2599526131626787fdc17
   "outputs": [],
   "source": [
    "# This reads in the json data\n",
    "# Try-except is just a fancy if-then statement that says if the file is not found, spit out the print statement (instead of\n",
    "#  the usual incomprehensible python error messages)\n",
    "try:\n",
    "    with open(\"Data/data_description.json\", \"r\") as fp:\n",
    "        data_description = json.load(fp)\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file was not found. Check that the Data directory is in the same directory as this file\")\n",
    "\n",
    "#data_channels = data_description[\"data_channels\"] #extracting data_channels as data_channels\n",
    "\n",
    "#size = np.size(data_channels)\n",
    "#print(size)\n",
    "#dimensions = len(data_channels[0])\n",
    "#print(dimensions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "### How many sensor data channels?\n",
    "\n",
    "TODO:  Figure out how many different data channels there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List [1, 2, 3]\n",
      "Sum of elements in list is: 1+2+3 = 6\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE, step 1\n",
    "\n",
    "my_test_dictionary = {\"Key 1 name\": \"Name\",\n",
    "                      \"Key 2 data list\": [1, 2, 3]}\n",
    "\n",
    "# Get list out of the dictionary\n",
    "list_from_dictionary = my_test_dictionary[\"Key 2 data list\"]\n",
    "print(f\"List {list_from_dictionary}\")\n",
    "\n",
    "# Sum up all of the elements in the list\n",
    "sum_elems = 0\n",
    "for item in list_from_dictionary:\n",
    "    sum_elems += item\n",
    "                    \n",
    "print(f\"Sum of elements in list is: 1+2+3 = {sum_elems}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO - use the key \"data_channels\" to get out the list of data channels from data_description\n",
    "\n",
    "data_channels = data_description[\"data_channels\"] #extracting data_channels as data_channels\n",
    "# How many elements does the list have in it?\n",
    "\n",
    "number_of_data_channels = np.size(data_channels)\n",
    "\n",
    "# TODO - Look in the Data/data_description.json file. Manually count how many channels there are. Put an\n",
    "#   assert statement here to check that the number_of_data_channels as the answer you would expect\n",
    "assert number_of_data_channels == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>read_json</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "read_json results: All test cases passed!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"read_json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "### Step 2: Loop over the data channels and add up the total number of dimensions\n",
    "\n",
    "TODO: Turn this pseudo code into real code\n",
    "\n",
    "- total number of channels = 0\n",
    "\n",
    "- for each channel in `data_channels` list\n",
    "   - add in the number of dimensions (key is \"dimensions\")\n",
    "\n",
    "Check in **S01C01.csv** that the number of dimensions you found matches the number of columns in the csv file.\n",
    "\n",
    "Stuck? Try printing out **`data_description`** and match that to what you see in the json file. Try getting the first element out (is it a list or a dictionary? How do you access a list or a dictionary element?) and printing it. Repeat until you're sure you know how to get the number of dimensions of the first channel.\n",
    "\n",
    "Now put it in a **for** loop, looping over the list. Print out each element in the list in the **for** loop.\n",
    "\n",
    "Now change the print statement to just print out the **dimensions** value.\n",
    "\n",
    "Now you can do the sum - you can use **`x = x + v`**.  OR **`x += v`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data channels items in list: 5, total summed number of dimensions: 13\n"
     ]
    }
   ],
   "source": [
    "n_total_dims = 0\n",
    "# TODO 1: turn this pseudo code into real code. \n",
    "# for each item in data channels\n",
    "#    Get the number of dimensions in that element and add it to n_total_dims\n",
    "# Note that each item in data channels is a dictionary - so you'll have to get the number out of the dictionary\n",
    "\n",
    "\n",
    "for channel in data_channels:\n",
    "    n_total_dims += channel[\"dimensions\"]\n",
    "\n",
    "# TODO: Fill out the print statement with the number of items in the data channels list, and \n",
    "# the total number of dimensions you calculated\n",
    "#     Again, you must actually calculate n_total_dims from data_channels - do NOT just set the number. What if someone\n",
    "#       added another channel to the data? Your code should still work...\n",
    "print(f\"Number of data channels items in list: {number_of_data_channels}, total summed number of dimensions: {n_total_dims}\")\n",
    "\n",
    "# TODO: Manually count the total number of dimensions. Write an assert statement that checks that the number of\n",
    "#   dimensions you calculated above is the same as the number you manually counted\n",
    "\n",
    "assert number_of_data_channels == 5\n",
    "assert n_total_dims == 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>number_dimensions</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "number_dimensions results: All test cases passed!"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"number_dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "### Data slicing to get out the right hand accelerometer data\n",
    "\n",
    "Practice slicing - pull out the X, Y, Z data for the right hand accelerometer at all timestamps for `S01C01.csv`.\n",
    "\n",
    "You are free to use the fact that the name of the data channel you want is \"Right hand accelerometer\", but you should get the actual offset index value from the dictionary, not just do `index_right_hand_accelerometer_start_index = 1` (suppose someone changed the order of the data...).\n",
    "\n",
    "There are several ways to do this; the simplest is to loop through all of the data channels looking for the one\n",
    "that is called \"Right hand accelerometer\" and then set the index offset value from that. It would be a good idea to check that you actually found the right starting index by looking at the .json file. Don't forget that numpy indexes from 0.\n",
    "\n",
    "Note: Use `==`, not `is`, for the string comparison. \n",
    "\n",
    "We'll do this in two parts (second part is next question): \n",
    "\n",
    "- TODO: Get the start index from the dictionary\n",
    "- TODO: Slice `clap_data` to get out just the right hand accelerometer x,y,z data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is in one dictionary entry:\n",
      " {'name': 'Left hand accelerometer', 'index_offset': 7, 'dimensions': 3, 'units': 'gravity units'}\n",
      "Channel Left hand accelerometer starts at 7\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE\n",
    "\n",
    "# These are examples of how to get data out of the data_description data structure\n",
    "#   Reminder that you already stored the list \"Data channels\" in the variable data_channels\n",
    "\n",
    "# Grab the fourth dictionary in the list of dictionaries\n",
    "get_fourth_dictionary_in_list = data_channels[3]\n",
    "\n",
    "# Look at data_description.json - this is one of the dictionaries in that file \n",
    "print(f\"What is in one dictionary entry:\\n {get_fourth_dictionary_in_list}\")\n",
    "\n",
    "# Using the \"name\" key to get the name stored in this dictionary\n",
    "name_in_dictionary = get_fourth_dictionary_in_list[\"name\"]\n",
    "\n",
    "# Using the \"start_index\" key to get the starting index\n",
    "start_index_in_dictionary = get_fourth_dictionary_in_list[\"index_offset\"]\n",
    "\n",
    "print(f\"Channel {name_in_dictionary} starts at {start_index_in_dictionary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset for right hand accelerometer: 1\n"
     ]
    }
   ],
   "source": [
    "# This is the name we're searching for. Using a variable so that we can change from Right hand accelerometer to something else later\n",
    "\n",
    "channel_name = \"Right hand accelerometer\"\n",
    "index_right_hand_accelerometer_offset = -1  #  Set it to a value that is NOT a valid index\n",
    "# TODO: Turn this pseudo code into real code\n",
    "# for each channel in data channels\n",
    "#     if this channel's name is the one I'm looking for\n",
    "#         set index_right_hand_accelerometer_offset to that channel's start index\n",
    "\n",
    "index = 0 #variable for storing index value\n",
    "\n",
    "for channel in data_channels: #loop to iterate through each channle\n",
    "    \n",
    "    if channel[\"name\"] == channel_name: #finding correct channel using name\n",
    "        index_right_hand_accelerometer_offset = index #defining RH accelerometer's offset\n",
    "        break\n",
    "\n",
    "    index += 1 #placed after since index starts at zero\n",
    "\n",
    "# Check that you actually set the value somewhere in the loop - this is \"defensive coding\"\n",
    "if index_right_hand_accelerometer_offset == -1:\n",
    "    print(f\"Error: No channel {channel_name} found\")\n",
    "\n",
    "print(f\"Offset for right hand accelerometer: {index_right_hand_accelerometer_offset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>channel_index</pre></strong> passed! üåà</p>"
      ],
      "text/plain": [
       "channel_index results: All test cases passed!"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"channel_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 2 - Now use slicing to get out all of the right hand accelerometer data\n",
    "\n",
    "The goal is to slice the data to get out a numpy array that is `n_time_steps`*`3`. The 3 is because we have x, y, and z data. This is a bit like the way **`my_test_data`** was created (create an empty array, set the x, then the y, then the z data)\n",
    "\n",
    "- First, use the slice operator to select all rows and columns, **data[:, :]**\n",
    "- Now change the column slice from all columns (:) to starting at the offset value you just calculated.\n",
    "- Now change the slice to end at the offset plus **3** (`n_dims_for_right_hand_accelerometer_data`)\n",
    "- Hint 1: slicing is  **start:end:step**\n",
    "- Hint 2: You need to index both the rows and the columns `[rows, cols]`. So you need one slice for the rows (this is the easy slice - you want all of the rows) and a second slice for which columns you want (this is the one that needs a `start:end:step` slice).\n",
    "- Hint 3: You don't need to put a step in; the default value of `1` is what you want since you are slicing adjacent columns.\n",
    "\n",
    "Remember: The data is in **`clap_data`**, not **`data_description`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "num_dimensions_test_data = 3  # x, y, z - we made the data with three channels\n",
    "index_offset_test_data = 4 # example index_offset\n",
    "\n",
    "# Get all of the columns beginning at index_offset_test_data and ending after num_dimensions_test_data columns\n",
    "#  The first : is all the rows, and the second item contains the range of columns to select\n",
    "just_xyz_test_data = my_test_data[:, index_offset_test_data:index_offset_test_data + num_dimensions_test_data]\n",
    "\n",
    "# Get the first column (timestamp)\n",
    "#   The first : is all the rows, the 0 is JUST the first row\n",
    "just_timestamps_test_data = my_test_data[:, 0]\n",
    "\n",
    "# TODO: Look at both of the above variables in the variable window\n",
    "\n",
    "# just_xyz_test_data should have the same number of rows as my_test_data, but just\n",
    "# contain 3 columns (the xyz data)\n",
    "expected_shape = (my_test_data.shape[0], num_dimensions_test_data)\n",
    "assert just_xyz_test_data.shape == expected_shape\n",
    "\n",
    "# And this one is number of rows * 1 size (use size, rather than shape, because shape could be many things)\n",
    "assert just_timestamps_test_data.size == 5\n",
    "\n",
    "# The number of time steps is equal to the number of rows\n",
    "n_time_steps_test_data = just_xyz_test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of right_hand_accelerometer_data is (101, 3), should be 101 X 3\n",
      "First row, first column value 0.70, should be 0.70\n",
      "First row, last column value -0.41, should be -0.41\n",
      "Last row, first column value 0.70, should be 0.70\n",
      "Last row, last column value 0.29, should be 0.29\n"
     ]
    }
   ],
   "source": [
    "# We know that this channel's data has x,y,z values (3 dimens). Use a variable instead of just the number 3\n",
    "#  in case we want to change it later\n",
    "n_dims_for_right_hand_accelerometer_data = 3\n",
    "# Create space for the data\n",
    "right_hand_accelerometer_data = np.zeros((n_time_steps, n_dims_for_right_hand_accelerometer_data))\n",
    "\n",
    "\n",
    "# TODO Fix this to copy the right hand accelerometer data into right_hand_accelerometer_data\n",
    "#  On the left-hand side, the columns should start at zero and end at 3 (n_dims_for_right_hand_accelerometer_data)\n",
    "#  On the right-hand side, the columns should start at index_wrist_torque_offset and end at index_wrist_torque_offset + 3 (n_dims_for_right_hand_accelerometer_data)\n",
    "\n",
    "#creating slicing variables\n",
    "right_hand_accelerometer_data_start = 1\n",
    "right_hand_accelerometer_data_stop = 4\n",
    "\n",
    "right_hand_accelerometer_data = clap_data[:, right_hand_accelerometer_data_start:right_hand_accelerometer_data_stop]\n",
    "\n",
    "#print(right_hand_accelerometer_data.shape[1])\n",
    "\n",
    "print(f\"Shape of right_hand_accelerometer_data is {right_hand_accelerometer_data.shape}, should be 101 X 3\")\n",
    "print(f\"First row, first column value {right_hand_accelerometer_data[0, 0]:0.2f}, should be 0.70\")\n",
    "print(f\"First row, last column value {right_hand_accelerometer_data[0, -1]:0.2f}, should be -0.41\")\n",
    "print(f\"Last row, first column value {right_hand_accelerometer_data[-1, 0]:0.2f}, should be 0.70\")\n",
    "print(f\"Last row, last column value {right_hand_accelerometer_data[-1, -1]:0.2f}, should be 0.29\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>slicing</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "slicing results: All test cases passed!"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Min/max/Mean/SD of x, y, and z values\n",
    "\n",
    "Now that the right hand accelerometer data is nicely separated out, find the min, max, mean and standard deviation of each of the x, y, and z channels. Put the result into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats [{'Min': np.float64(0.0), 'Max': np.float64(19.56077839534729)}]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE\n",
    "# Get the min/max of the x values of the test code (should be 0 and 1) and store it in a dictionary\n",
    "\n",
    "# Since we have x,y, and z, we'll want a list to store the stats for each dimension\n",
    "my_list_of_stats = []\n",
    "\n",
    "# Since we need to do both min and max, create a variable that has the x slice\n",
    "#    The : says all of the rows, start at 0 and skip every 3rd\n",
    "x_slice = my_test_data[:, 0::3]\n",
    "\n",
    "# Put the results of min/max in a dictionary\n",
    "my_dict = {\"Min\" : np.min(x_slice),\n",
    "           \"Max\" : np.max(x_slice)}\n",
    "\n",
    "# Put the dictionary with the x min and max into the list\n",
    "my_list_of_stats.append(my_dict)\n",
    "\n",
    "print(f\"Stats {my_list_of_stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# SCRATCH CELL\n",
    "# Try editing the above code to do the y and z channels as well - the result should be a list with three elements\n",
    "#  Option 1: Copy the code (from x_slice through the append) and then change 0 to 1 to do the y channel.\n",
    "#  Option 2: Use a for loop over i=0,1,2 and change the 0 to an i\n",
    "#    Change the variable name from x_slice to something like cur_slice, since it will be the x slice, then the y, then the z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "right_hand_accelerometer_stats_list = []\n",
    "\n",
    "\n",
    "# TODO For each of the x,y, and z data channels, calculate the min, max, mean and standard deviation. \n",
    "#   Store the values in a dictionary with the keys \"Min\", \"Max\", \"Mean\", and \"SD\"\n",
    "#   Put the dictionaries into the right_hand_accelerometer_stats_list list\n",
    "# Your output should look like Data/Lab1_check_results.json\n",
    "\n",
    "#creating slicing variable\n",
    "data_slice = [1,2,3] #index for x,y,z\n",
    "\n",
    "n_dimensions = 3\n",
    "for axis in range(n_dimensions): #loops for how many dimensions exist\n",
    "    stats = {\n",
    "        \"Min\": np.min(clap_data[:, data_slice[axis]]),\n",
    "        \"Max\": np.max(clap_data[:, data_slice[axis]]),\n",
    "        \"Mean\": np.mean(clap_data[:, data_slice[axis]]),\n",
    "        \"SD\": np.std(clap_data[:, data_slice[axis]])\n",
    "    }\n",
    "    right_hand_accelerometer_stats_list.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST CODE\n",
    "#   The correct answers are in Lab1_check_results.json. You can write test code here to check\n",
    "#   each value in turn, make sure the slicing is the correct size. This will not be graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# These commands will force JN to actually re-load the external file when you re-execute the imort command\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>statistics</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "statistics results: All test cases passed!"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Boolean slicing to get time slices for different types of hand motions\n",
    "\n",
    "TODO: Load up the first hand motion file for each hand motion type for subject 1 into a single numpy array, and calculate the mean z value for the right hand accelerometer for each motion type.\n",
    "\n",
    "The main difference between this problem and the previous one is that in this one you only use some of the rows (instead of all of them like the last problem). The column slice stays the same, but the row slice changes. We're going to use Boolean indexing to do this.\n",
    "\n",
    "- Step 1: Load up the first hand motion file for each hand motion type for subject 1 (`Data/S01F01.csv` and `Data/S01S01.csv`; `Data/S01C01.csv` is already loaded into `clap_data`). (Note, those are zeros, not capital O's)\n",
    "- Step 2: Store the right hand accelerometer data from all three of those files into a single numpy array with an additional column encoding the motion type (snap, high-five, clap). \n",
    "- Step 3: Create a boolean index that is True if the row is for a \"clap\", False if it is not.\n",
    "- Step 4: Use the boolean index to select the rows - only select rows where the index is True -- and then calculate the mean z value for the right hand accelerometer.\n",
    "- Step 5: Do the same thing again, but this time select rows that are for \"high-five\".\n",
    "- Step 6: Do the same thing again, but this time select rows that are for \"snap\".\n",
    "\n",
    "This exercise may seem somewhat pointless, since the data is already separated by motion type when you load it in from the individual files. But it is useful practice for operating on a large combined dataset, which you will be doing in the Homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Step 1: Loading up other motion types.\n",
    "\n",
    "Load up the first hand motion file for each hand motion type for subject 1 (`Data/S01F01.csv` and `Data/S01S01.csv`; `Data/S01C01.csv` is already loaded into `clap_data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO Load high five data from Data/S01F01.csv into high_five_data and snap data from Data/S01S01.csv into snap_data\n",
    "\n",
    "high_five_data = np.loadtxt(fname=\"Data/S01F01.csv\", dtype=\"float\", delimiter=',')\n",
    "snap_data = np.loadtxt(fname=\"Data/S01S01.csv\", dtype=\"float\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Numeric ids to indicate hand motion type.\n",
    "# All of the data in a numpy array has to be of the same type (e.g., floats),\n",
    "# so these IDs map hand motions to floats.\n",
    "clap_id = 1\n",
    "high_five_id = 2\n",
    "snap_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# EXAMPLE CODE\n",
    "\n",
    "# Let's add a column to indicate the motion type of each row to the data. We will combine two copies of my_test_data\n",
    "# (since we only have one fake data set), but pretend that each is for a different motion type.\n",
    "\n",
    "# Allocate space for the right hand accelerometer data, adding a column for motion type.\n",
    "# We need to allocate more rows since we are putting my_test_data in here twice.\n",
    "my_test_data_with_motion_ids = np.zeros((my_test_data.shape[0] + my_test_data.shape[0], num_dimensions_test_data + 1))\n",
    "\n",
    "# Copy over my_test_data the first time (pretend clap data)\n",
    "my_test_data_with_motion_ids[0:my_test_data.shape[0], 0:num_dimensions_test_data] = my_test_data[:, index_offset_test_data:index_offset_test_data + num_dimensions_test_data]\n",
    "\n",
    "# Copy over my_test_data the second time (pretend snap data)\n",
    "my_test_data_with_motion_ids[my_test_data.shape[0]:my_test_data.shape[0] + my_test_data.shape[0], 0:num_dimensions_test_data] = my_test_data[:, index_offset_test_data:index_offset_test_data + num_dimensions_test_data]\n",
    "\n",
    "# Populate column for motion id for the first data set. -1 means get the last column.\n",
    "my_test_data_with_motion_ids[0:my_test_data.shape[0], -1] = clap_id\n",
    "\n",
    "# Populate column for motion id for the second data set (pretend snap data).\n",
    "my_test_data_with_motion_ids[my_test_data.shape[0]:my_test_data.shape[0] + my_test_data.shape[0], -1] = snap_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Put the right hand accelerometer data from clap_data, snap_data, and high_five_data into all_right_hand_accelerometer_data, and add an extra column\n",
    "# that encodes the motion type for each row.\n",
    "# This should be a numpy array that is the number of rows of clap, high five, and snap combined, with 4 columns (x,y,z,id)\n",
    "\n",
    "#variables for empty array variables\n",
    "tot_rows = clap_data.shape[0] + snap_data.shape[0] + high_five_data.shape[0]\n",
    "tot_columns = num_dimensions_test_data + 1 #+1 to for motion id\n",
    "\n",
    "#creating empty array\n",
    "all_right_hand_accelerometer_data = np.zeros((tot_rows, tot_columns))\n",
    "\n",
    "#populating with clap data\n",
    "all_right_hand_accelerometer_data[0:clap_data.shape[0], 0:num_dimensions_test_data] = clap_data[:, index_right_hand_accelerometer_offset:index_right_hand_accelerometer_offset + num_dimensions_test_data]\n",
    "\n",
    "#populating with snap data\n",
    "all_right_hand_accelerometer_data[clap_data.shape[0]:clap_data.shape[0] + snap_data.shape[0], 0:num_dimensions_test_data] = snap_data[:, index_right_hand_accelerometer_offset:index_right_hand_accelerometer_offset + num_dimensions_test_data]\n",
    "\n",
    "#populating with high five data\n",
    "all_right_hand_accelerometer_data[clap_data.shape[0] + snap_data.shape[0]:tot_rows, 0:num_dimensions_test_data] = high_five_data[:, index_right_hand_accelerometer_offset:index_right_hand_accelerometer_offset + num_dimensions_test_data]\n",
    "\n",
    "#populating with motion IDs\n",
    "all_right_hand_accelerometer_data[0:clap_data.shape[0], -1] = clap_id\n",
    "all_right_hand_accelerometer_data[clap_data.shape[0]:clap_data.shape[0] + snap_data.shape[0], -1] = snap_id\n",
    "all_right_hand_accelerometer_data[clap_data.shape[0] + snap_data.shape[0]:, -1] = high_five_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claps: Avg value 0.4186 of right hand accelerometer z channel\n",
      "High five: Avg value -0.5571 of right hand accelerometer z channel\n",
      "Snap: Avg value -1.1496 of right hand accelerometer z channel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Create a boolean array to pick out the clap rows\n",
    "bool_array_claps = all_right_hand_accelerometer_data[:, -1] == clap_id\n",
    "\n",
    "# TODO: Now use that boolean array plus column slicing to calculate the avg of the z values\n",
    "avg_right_hand_accelerometer_clap_z = np.mean(all_right_hand_accelerometer_data[bool_array_claps, 2])\n",
    "\n",
    "\n",
    "# TODO: Repeat for high-fives\n",
    "bool_array_high_fives = all_right_hand_accelerometer_data[:, -1] == high_five_id\n",
    "avg_right_hand_accelerometer_high_five_z = np.mean(all_right_hand_accelerometer_data[bool_array_high_fives, 2])\n",
    "\n",
    "\n",
    "# TODO: Repeat for snaps\n",
    "bool_array_snaps = all_right_hand_accelerometer_data[:, -1] == snap_id\n",
    "avg_right_hand_accelerometer_snap_z = np.mean(all_right_hand_accelerometer_data[bool_array_snaps, 2])\n",
    "\n",
    "\n",
    "print(f\"Claps: Avg value {avg_right_hand_accelerometer_clap_z:0.4f} of right hand accelerometer z channel\")\n",
    "print(f\"High five: Avg value {avg_right_hand_accelerometer_high_five_z:0.4f} of right hand accelerometer z channel\")\n",
    "print(f\"Snap: Avg value {avg_right_hand_accelerometer_snap_z:0.4f} of right hand accelerometer z channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>boolean_slicing</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "boolean_slicing results: All test cases passed!"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"boolean_slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"n/a\"}\n",
    "# List of URLS 2S5 (creates a set)\n",
    "websites = {\"https://numpy.org/doc/stable/reference/generated/numpy.std.html, https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>hours_collaborators</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "hours_collaborators results: All test cases passed!"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To submit\n",
    "\n",
    "- Do a clear all outputs,  restart, then run all to make sure everything runs ok\n",
    "- Remove print statements that print out a lot of stuff\n",
    "- Save the file\n",
    "- Submit just this .ipynb file through gradescope, lab 1 data analysis\n",
    "- You do NOT need to submit the data files - we will supply those\n",
    "\n",
    "If the Gradescope autograder fails, please check here first for common reasons for it to fail https://docs.google.com/presentation/d/1tYa5oycUiG4YhXUq5vHvPOpWJ4k_xUPp2rUNIL7Q9RI/edit?usp=sharing\n",
    "\n",
    "Most likely failure for this assignment is not naming the data directory and files correctly; capitalization matters for the Gradescope grader."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "boolean_slicing": {
     "name": "boolean_slicing",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(high_five_data[0, 0], 27084.0, atol=0.01)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(snap_data[0, 0], 62445.0, atol=0.01)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all_right_hand_accelerometer_data.shape[0] == clap_data.shape[0] + high_five_data.shape[0] + snap_data.shape[0]\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all_right_hand_accelerometer_data.shape[1] == 4\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.sum(all_right_hand_accelerometer_data[:, -1] == clap_id) == clap_data.shape[0]\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.sum(all_right_hand_accelerometer_data[:, -1] == snap_id) == snap_data.shape[0]\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.sum(all_right_hand_accelerometer_data[:, -1] == high_five_id) == high_five_data.shape[0]\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(avg_right_hand_accelerometer_clap_z, 0.4186138, atol=0.01)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(avg_right_hand_accelerometer_high_five_z, -0.5570526, atol=0.01)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(avg_right_hand_accelerometer_snap_z, -1.14955056, atol=0.01)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "channel_index": {
     "name": "channel_index",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert index_right_hand_accelerometer_offset == 1\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "count_rows": {
     "name": "count_rows",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert clap_data.shape[0] == 101\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert n_time_steps == 101\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert n_pos_z == 53\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert n_neg_z == 48\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not 'not filled out' in worked_with_names\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not 'not filled out' in websites\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert hours > 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "number_dimensions": {
     "name": "number_dimensions",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert n_total_dims == 13\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "read_json": {
     "name": "read_json",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(data_channels) == len(data_description['data_channels'])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert len(data_channels) == 5\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "slicing": {
     "name": "slicing",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert right_hand_accelerometer_data.shape[0] == clap_data.shape[0]\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert right_hand_accelerometer_data.shape[1] == 3\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(right_hand_accelerometer_data[0, 0], 0.7)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(right_hand_accelerometer_data[0, -1], -0.41)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(right_hand_accelerometer_data[-1, 0], 0.7)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(right_hand_accelerometer_data[-1, -1], 0.29)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "statistics": {
     "name": "statistics",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from check_json_answers import compare_files\n>>> assert compare_files(right_hand_accelerometer_stats_list, 'Lab1_check_results.json')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
