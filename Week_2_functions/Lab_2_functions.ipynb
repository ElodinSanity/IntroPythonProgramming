{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Lab_2_functions.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Statistical analysis of data using numpy\n",
    "\n",
    "Lab slides: (https://docs.google.com/presentation/d/1ykwwcQ0onMvAjUxfJmKl9tbo-rJPdB5pRwDEmpDsd-g/edit?usp=sharing)\n",
    "\n",
    "For this lab the goal is to write functions to pull out one data channel and print out statistics for different types of hand motions. We will write a function to load data from a single file, a second to combine data from multiple files, a third to pull out the data for a selected data channel, then a fourth to calculate statistics.\n",
    "\n",
    "Written properly, you only need one function to do stats for the entire data channel or for just one type of hand motion. For any data channel. In the homework you'll use this logic to apply statistics to a specific data channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that we need to import - numpy and json (for loading the description file)\n",
    "import numpy as np\n",
    "import json as json\n",
    "# os is needed for calling os.path.basename\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Reading in data\n",
    "\n",
    "Based on your code from Lab 1, write a function `get_data` that loads the data from a single CSV and adds a column at the end containing the hand motion ID. Then, write a function `get_data_from_files` that loads data from a list of CSV files into a single numpy array using `get_data`.\n",
    "\n",
    "Both functions will operate on a dictionary containing `\"csv_path\"` which holds the path to the data file and `\"motion_id\"` which holds the ID of the motion contained within the CSV file. You will write a third function `get_file_info` that returns this dictionary for a given CSV file, which will extract the motion type from the file name.\n",
    "\n",
    "Note: The functions initially just contain `pass`, which is just a placeholder that you should remove. In Python, `pass` does nothing at all by design, but removing it and having an empty function is illegal ([docs](https://docs.python.org/3/tutorial/controlflow.html#pass-statements))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Numeric ids to indicate hand motion type from Lab 1\n",
    "clap_id = 1\n",
    "high_five_id = 2\n",
    "snap_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCRATCH cell\n",
    "fname_chop_up = \"Data/S01C01.csv\"\n",
    "res = os.path.basename(fname_chop_up)\n",
    "\n",
    "# TODO:  look at res. How would you get out the C F or S character?\n",
    "middle_char = res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Write the function to take csv_path and return a dictionary\n",
    "# Step 1: Use `os.path.basename` to get the filename of the CSV file (e.g., S10F01.csv),\n",
    "# Step 2: Extract the C/F/S character which will appear at a fixed offset in the filename,\n",
    "# and then \n",
    "# Step 3: find the right motion ID based on that character. Remember that C is a\n",
    "# clap, F is a high five, and S is a snap.\n",
    "# Step 4: Make a dictionary and return it (see @return for details)\n",
    "def get_file_info(csv_path):\n",
    "    \"\"\"Function that returns a file_info dictionary for a given filepath.\n",
    "    @param csv_path - path to a CSV file containing a hand motion\n",
    "    @return A dictionary with key \"csv_path\", containing csv_path, and \"motion_id\", containing the type of motion encoded in the file.\"\"\"\n",
    "    # The base file path is of the form S##[C|F|S]##.csv.\n",
    "\n",
    "    file_char = os.path.basename(csv_path)[3] #extracting C, F, or S from filename\n",
    "\n",
    "    motion_id = 0 #creating varaible to hold motion id number\n",
    "\n",
    "    #checks for char and assigns correct motion id\n",
    "    if file_char == 'C':\n",
    "        motion_id = clap_id\n",
    "    elif file_char == 'F':\n",
    "        motion_id = high_five_id\n",
    "    elif file_char == 'S':\n",
    "        motion_id = snap_id\n",
    "\n",
    "    return {'csv_path' : csv_path, 'motion_id' : motion_id}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell: If you wrote the above function correctly, this should work!\n",
    "assert(get_file_info(\"Data/S01C01.csv\") == {\"csv_path\": \"Data/S01C01.csv\", \"motion_id\": clap_id})\n",
    "\n",
    "# TODO... Write another assert test for the high five data \n",
    "assert(get_file_info('Data/S01F01.csv') == {\"csv_path\": \"Data/S01F01.csv\", \"motion_id\": high_five_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Actually read in the data and add the motion id to the end\n",
    "#   Reminder: file_info will be the dictionary you just created in the above function\n",
    "def get_data(file_info):\n",
    "    \"\"\" Function that returns the data from the given CSV file.\n",
    "    @param file_info - a dictionary with keys \"csv_path\" and \"motion_id\"\n",
    "    @return Return array should contain data in file with an extra column at the end containing the motion_id.\"\"\"\n",
    "\n",
    "    fname = file_info[\"csv_path\"] #extracting file name from file_info argument\n",
    "\n",
    "    file_data = np.loadtxt(fname=fname, dtype=\"float\", delimiter=',') #reading desired file\n",
    "\n",
    "    arr_shape = np.shape(file_data) #getting shape of data set\n",
    "\n",
    "    rows = arr_shape[0] #variable for number of rows\n",
    "    columns = arr_shape[-1] #variable for number of columns\n",
    "\n",
    "    read_data = np.zeros((rows, columns + 1)) #creating empty array for data + motion id\n",
    "\n",
    "    read_data[:,0:columns] = file_data #inserting data into new array\n",
    "\n",
    "    read_data[:,-1] = file_info[\"motion_id\"] #assignming motion id\n",
    "\n",
    "    return read_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell: TODO: Write a test that \n",
    "#   Calls get_file_info to create a dictionary\n",
    "#   Passes that dictionary to get_data\n",
    "#   Checks that the returned data is correct\n",
    "#     1) the last column is the expected motion id\n",
    "#     2) the data is correct\n",
    "\n",
    "#calling functions\n",
    "file_info = get_file_info(\"Data/S01C01.csv\")\n",
    "file_data = get_data(file_info)\n",
    "\n",
    "\n",
    "original_data = np.loadtxt(fname=\"Data/S01C01.csv\", dtype=\"float\", delimiter=',') #reading orginal data\n",
    "\n",
    "assert np.all(file_data[:,-1]) == float(file_info[\"motion_id\"]) #checking that the motion id is correct\n",
    "assert np.allclose(file_data[:, 0:-1], original_data) #checking that the data in the file_data array is the same as the original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: This function reads in multiple data sets (not just one)\n",
    "#  Reminder: Each element of file_list is a dictionary \n",
    "#   You should be calling your get_data function from this function...\n",
    "def get_data_from_files(file_list):\n",
    "    \"\"\" Function that returns data from a list of files.\n",
    "    @param file_list - a list of dictionaries, where each dictionary contains `csv_path` and `motion_id`.\n",
    "    @return A single return array containing the data from all of the given input files.\"\"\"\n",
    "    # Hint: Use np.concatenate to combine multiple numpy arrays.\n",
    "    \n",
    "    all_data = [] #empty list for all of the data\n",
    "\n",
    "    for file in file_list: #loops through each file\n",
    "        data = get_data(file) #gets data from n file in list\n",
    "        all_data.append(data) #appends file data onto all_data (list of arrays)\n",
    "    \n",
    "    return np.concatenate(all_data) #returns a combination of all arrays in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCRATCH cell\n",
    "# TODO: Use this cell to check that all three functions are working correctly\n",
    "original_data = np.loadtxt(fname=\"Data/S01C01.csv\", dtype=\"float\", delimiter=',') #reading orginal data\n",
    "file_info = get_file_info(\"Data/S01C01.csv\")\n",
    "all_data_check = get_data_from_files([get_file_info(\"Data/S01C01.csv\")])\n",
    "\n",
    "assert np.all(all_data_check[:,-1]) == float(file_info[\"motion_id\"]) #checking that the motion id is correct\n",
    "assert np.allclose(all_data_check[:, 0:-1], original_data) #checking that the data in the file_data array is the same as the original data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in data from the files in lab 1 using the functions you just wrote.\n",
    "all_data = get_data_from_files([\n",
    "    get_file_info(\"Data/S01C01.csv\"),\n",
    "    get_file_info(\"Data/S01F01.csv\"),\n",
    "    get_file_info(\"Data/S01S01.csv\"),\n",
    "])\n",
    "\n",
    "# The autograder will check that get_file_info is correct, then that\n",
    "#  the last columns of all_data are set to the correct motion ids,\n",
    "# then check that the actual data in all_data is correct\n",
    "# Reminder that you can look in the files (eg, S01F01.csv) to see what the values should be\n",
    "# Reonder 2: If you have print statements in your functions that will also cause the autograder to fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>get_data</pre></strong> passed! 🍀</p>"
      ],
      "text/plain": [
       "get_data results: All test cases passed!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"get_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Doing the slice\n",
    "\n",
    "Get the data for one of the channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# This reads in the json data\n",
    "try:\n",
    "    with open(\"Data/data_description.json\", \"r\") as fp:\n",
    "        data_description = json.load(fp)\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file was not found; check that the data directory is in the current one and the file is in that directory\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Return the descriptor dictionary for the given name\n",
    "#  Reminder that data_description is a dictionary with the \"data channels\" key\n",
    "#   containing the list of dictionaries...\n",
    "def get_descriptor(data_description, name):\n",
    "    \"\"\" Search through data_description to find the dictionary with name \"name\"\n",
    "    @param name - The name of the data channel to look for. \n",
    "    @return the dictionary that has name as the 'name' key\"\"\"\n",
    "\n",
    "    for description in data_description[\"data_channels\"]:\n",
    "        if description[\"name\"] == name: #if the name element is the desired name\n",
    "            return description #return the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Write a test that, eg, get_descriptor with \"Timestamp\" returns the first dictionary\n",
    "#  in the list in data_description.json\n",
    "\n",
    "test_description = get_descriptor(data_description, \"Timestamp\")\n",
    "\n",
    "#checks get_descriptor against first element of data_channels (name = Timestamp)\n",
    "assert test_description == data_description[\"data_channels\"][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO get the channel data that starts at index_offset and has n_dims\n",
    "def get_channel_data(all_data, index_offset, n_dims):\n",
    "    \"\"\" Get the data for just one channel (e.g., right hand accelerometer)\n",
    "    @param all_data - numpy array containing data from one (or more) files\n",
    "    @param index_offset - the column to begin getting data from\n",
    "    @param n_dims - number of dimensions for the data channel\n",
    "    @return Returned array should be: number of rows in all_data X n_dims\"\"\"\n",
    "\n",
    "    return all_data[:, index_offset : index_offset + n_dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test 1 - the right hand accelerometer data\n",
    "rh_accelerometer_descriptor = get_descriptor(data_description, \"Right hand accelerometer\")\n",
    "rh_accelerometer_data = get_channel_data(all_data, index_offset=rh_accelerometer_descriptor[\"index_offset\"], n_dims=rh_accelerometer_descriptor[\"dimensions\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of rhs_accelerometer_data is (285, 3), should be 285 X 3\n",
      "First row, first column value 0.70, should be 0.70\n",
      "First row, last column value -0.41, should be -0.41\n",
      "Last row, first column value 0.07, should be 0.07\n",
      "Last row, last column value -0.98, should be -0.98\n"
     ]
    }
   ],
   "source": [
    "# SELF TESTS\n",
    "print(f\"Shape of rhs_accelerometer_data is {rh_accelerometer_data.shape}, should be 285 X 3\")\n",
    "print(f\"First row, first column value {rh_accelerometer_data[0, 0]:0.2f}, should be 0.70\")\n",
    "print(f\"First row, last column value {rh_accelerometer_data[0, -1]:0.2f}, should be -0.41\")\n",
    "print(f\"Last row, first column value {rh_accelerometer_data[-1, 0]:0.2f}, should be 0.07\")\n",
    "print(f\"Last row, last column value {rh_accelerometer_data[-1, -1]:0.2f}, should be -0.98\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests for Left hand gyroscope\n",
    "lh_gyroscope_descriptor = get_descriptor(data_description, \"Left hand gyroscope\")\n",
    "lh_gyroscope_data = get_channel_data(all_data, index_offset=lh_gyroscope_descriptor[\"index_offset\"], n_dims=lh_gyroscope_descriptor[\"dimensions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check size and first, last element\n",
    "assert(lh_gyroscope_data.shape == (all_data.shape[0], 3))\n",
    "assert(np.isclose(lh_gyroscope_data[0, 0], 429.34))\n",
    "assert(np.isclose(lh_gyroscope_data[-1, -1], -154.36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>check_slice</pre></strong> passed! 🍀</p>"
      ],
      "text/plain": [
       "check_slice results: All test cases passed!"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"check_slice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Compute stats: Write a function to calculate the four stats\n",
    "\n",
    "This is a variation on what you did in lab 1; in this case, we're going to do it with two functions. The first calculates the stats and returns the dictionary (**calc_stats**) the second does the **for** loop to make one dictionary for each dimension in the data.\n",
    "\n",
    "- Step 1 [this problem] - do the **calc_stats** function\n",
    "- Step 2 [next problem] - do the loop to calculate the stats for each x,y,z channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Fill in the function that calculates the stats for the data\n",
    "def calc_stats(data):\n",
    "    \"\"\"Calculate min, max, mean and standard deviation for the array and put in a dictionary\n",
    "    @param data a numpy array\n",
    "    @return a dictionary with the given keys\"\"\"\n",
    "\n",
    "    # Use keys Min, Max, Mean, and SD\n",
    "    return {\n",
    "        \"Min\": np.min(data),\n",
    "        \"Max\": np.max(data),\n",
    "        \"Mean\": np.mean(data),\n",
    "        \"SD\": np.std(data)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the function with known data\n",
    "test_data = np.linspace(0, 1, 10)\n",
    "ret_dict = calc_stats(test_data)\n",
    "\n",
    "assert(np.isclose(ret_dict[\"Min\"], 0.0))\n",
    "assert(np.isclose(ret_dict[\"Max\"], 1.0))\n",
    "assert(np.isclose(ret_dict[\"Mean\"], 0.5))\n",
    "assert(np.isclose(ret_dict[\"SD\"], 0.319, atol=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>stats_channel</pre></strong> passed! 🙌</p>"
      ],
      "text/plain": [
       "stats_channel results: All test cases passed!"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"stats_channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Now do the second half - \n",
    "\n",
    "This function calculates the stats for an entire channel of the data, and stores the result in a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_stats_for_channel(data, n_dims):\n",
    "    \"\"\" Calculate the stats for a channel\n",
    "    @param data - an n_timestamps * n_dims size array\n",
    "    @param n_dims - 1, 2, or 3 (just x; x,y; or x,y,z)\n",
    "    @return A list of dictionaries. The list is the length of n_dims\"\"\"\n",
    "\n",
    "    stats_list = []\n",
    "    # TODO Copy in your for loop from the statistics problem in Lab 1\n",
    "    # If you didn't do a for loop in lab 1, you need to make it a for loop now!\n",
    "    # - You DO need to slice the data into the x,y,z channels\n",
    "    # - You need to loop n_dims times\n",
    "    # - Don't forget to return the array\n",
    "    \n",
    "    dim = 1 #index for dimention\n",
    "\n",
    "    for dim in range(n_dims): #loops for how many dimensions exist\n",
    "        stats = {\n",
    "            \"Min\": np.min(data[:, dim]),\n",
    "            \"Max\": np.max(data[:, dim]),\n",
    "            \"Mean\": np.mean(data[:, dim]),\n",
    "            \"SD\": np.std(data[:, dim])\n",
    "        }\n",
    "        dim += 1 #increments dimension\n",
    "        stats_list.append(stats) #adding stats of dim dimension\n",
    "\n",
    "    return stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCRATCH CELL\n",
    "# If you're having trouble, try setting n_dims to 1 and use test_data for the data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing with known data - make a fake data set with 5 time steps and x, y, z data\n",
    "#  \n",
    "test_stats = np.zeros((5, 3))\n",
    "# Set the x data to be ones\n",
    "test_stats[:, 0] = np.ones(5)\n",
    "# Set the y data to be twos\n",
    "test_stats[:, 1] = np.ones(5) * 2\n",
    "# Set the z data to be threes\n",
    "test_stats[:, 2] = np.ones(5) * 3\n",
    "\n",
    "# Now get the actual stats\n",
    "ret_stats_array = calc_stats_for_channel(test_stats, n_dims=3)\n",
    "\n",
    "# Check the mean result for x, y, and z - should be 1, 2, and 3 respectively\n",
    "assert(ret_stats_array[0][\"Mean\"] == 1.0)\n",
    "assert(ret_stats_array[1][\"Mean\"] == 2.0)\n",
    "assert(ret_stats_array[2][\"Mean\"] == 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this should work\n",
    "ret_stats_rh_accelerometer = calc_stats_for_channel(rh_accelerometer_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As should this\n",
    "res_stats_lh_gyroscope = calc_stats_for_channel(lh_gyroscope_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>loop_data_calc_stats</pre></strong> passed! 🌟</p>"
      ],
      "text/plain": [
       "loop_data_calc_stats results: All test cases passed!"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"loop_data_calc_stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Boolean slicing to get successful versus unsuccessful statistics out\n",
    "\n",
    "Use the functions you just wrote to get out the min and max z values for each type of hand motion.\n",
    "\n",
    "For this problem I have written code that is *incorrect*. You know the functions themselves are correct - you just tested them. The following bits of code have something wrong with either the way the function is called OR with the way the results are gotten back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clap: Minimum -1.04 and maximum 9.06 value of right hand accelerometer z channel\n",
      "Snap: Minimum -2.77 and maximum 1.05 value of right hand accelerometer z channel\n",
      "High five: Minimum -0.74 and maximum -0.32 value of right hand accelerometer z channel\n"
     ]
    }
   ],
   "source": [
    "# Boolean filters for getting rows for a specific motion type. \n",
    "# Motion type should extract the last columnb in the data\n",
    "#   uncomment and get the last column\n",
    "motion_type = all_data[:, -1]\n",
    "\n",
    "# These should match the specific IDs for each motion type, eg clap_id.\n",
    "# Uncomment and compare motion type to the appropriate XX_id \n",
    "b_clap = motion_type == clap_id\n",
    "b_snap = motion_type == snap_id\n",
    "b_high_five = motion_type == high_five_id\n",
    "\n",
    "# Use b_clap to pick out the rows that are for claps. Send all column data for the selected rows.\n",
    "#   Right hand accelerometer has 3 dimensions (x,y,z)\n",
    "#   There's two errors here - one that actually will create incorrect results, one that just *happens* to work\n",
    "#   correctly, although it doesn't do what the first sentance says...\n",
    "ret_rh_accelerometer_clap = calc_stats_for_channel(rh_accelerometer_data[b_clap], n_dims=3)\n",
    "\n",
    "# The minimum should be in the third (last) element in the list, the \"min\" key\n",
    "z_min_clap = ret_rh_accelerometer_clap[2][\"Min\"]\n",
    "z_max_clap = ret_rh_accelerometer_clap[2][\"Max\"]\n",
    "\n",
    "# Now, do the same thing above, but for snap and high_five\n",
    "\n",
    "ret_rh_accelerometer_snap = calc_stats_for_channel(rh_accelerometer_data[b_snap], n_dims=3) #finds stats for snap data\n",
    "z_min_snap = ret_rh_accelerometer_snap[2][\"Min\"] #indexes to z and min\n",
    "z_max_snap = ret_rh_accelerometer_snap[2][\"Max\"] #indexes to z and max\n",
    "\n",
    "ret_rh_accelerometer_high_five = calc_stats_for_channel(rh_accelerometer_data[b_high_five], n_dims=3) #finds stats for high five data\n",
    "z_min_high_five = ret_rh_accelerometer_high_five[2][\"Min\"] #indexes to z and min\n",
    "z_max_high_five = ret_rh_accelerometer_high_five[2][\"Max\"] #indexes to z and max\n",
    "\n",
    "print(f\"Clap: Minimum {z_min_clap} and maximum {z_max_clap} value of right hand accelerometer z channel\")\n",
    "print(f\"Snap: Minimum {z_min_snap} and maximum {z_max_snap} value of right hand accelerometer z channel\")\n",
    "print(f\"High five: Minimum {z_min_high_five} and maximum {z_max_high_five} value of right hand accelerometer z channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>boolean_slicing</pre></strong> passed! 💯</p>"
      ],
      "text/plain": [
       "boolean_slicing results: All test cases passed!"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"boolean_slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Optional/Extra credit: print out all of the rows where the minimum z value for a clap motion was reached\n",
    "\n",
    "See the tutorial on **np.where** (c_tutorial_where.ipynb)\n",
    "\n",
    "TODO: Use **np.where** to pick out the row that has the minimum z value for a clap motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO Use np.where to get out the indices. You can use == OR np.isclose() here; either works. In general, use .isclose for \n",
    "#  floating point comparisons.\n",
    "# Append the row number of any matches to this list\n",
    "all_rows_with_min = []\n",
    "#row = 0\n",
    "#for element in rh_accelerometer_data[:,2]:\n",
    "    #if np.isclose(element, z_min_clap):\n",
    "        #all_rows_with_min.append(row)\n",
    "        \n",
    "    #elif np.isclose(element, z_min_snap):\n",
    "        #all_rows_with_min.append(row)\n",
    "        \n",
    "    #elif np.isclose(element, z_min_high_five):\n",
    "        #all_rows_with_min.append(row)\n",
    "        \n",
    "    #row += 1\n",
    "\n",
    "conditions = (np.isclose(rh_accelerometer_data[b_clap][:,2], z_min_clap))\n",
    "\n",
    "all_rows_with_min = np.where(conditions)[0]\n",
    "\n",
    "#print(all_rows_with_min)\n",
    "# Look at JUST the z values in rh_accelerometer_data\n",
    "#all_indices_from_where = np.where\n",
    "\n",
    "# Pseudo code - see tutorial for exact format\n",
    "# for all row in all_indices_from_where\n",
    "#    if this is row is from a clap: \n",
    "#       print(f\"Row: {r}, Time step: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>optional_where</pre></strong> passed! 🎉</p>"
      ],
      "text/plain": [
       "optional_where results: All test cases passed!"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"optional_where\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"N/A\"}\n",
    "# List of URLS 2S5 (creates a set)\n",
    "websites = {\"https://numpy.org/doc/stable/reference/generated/numpy.std.html\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>hours_collaborators</pre></strong> passed! 💯</p>"
      ],
      "text/plain": [
       "hours_collaborators results: All test cases passed!"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To submit\n",
    "\n",
    "- Do a restart then run all to make sure everything runs ok\n",
    "- Save the file\n",
    "- Submit just this .ipynb file through gradescope, Lab 2, functions\n",
    "- You do NOT need to submit the data files - we will supply those\n",
    "- Where there are given variable/file names (eg, foo = ...) DON'T change those, or the autograder will fail\n",
    "\n",
    "If the Gradescope autograder fails, please check here first for common reasons for it to fail\n",
    "    https://docs.google.com/presentation/d/1tYa5oycUiG4YhXUq5vHvPOpWJ4k_xUPp2rUNIL7Q9RI/edit?usp=sharing\n",
    "\n",
    "Most likely failure for this assignment is not naming the data directory and files correctly; capitalization matters for the Gradescope grader. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "boolean_slicing": {
     "name": "boolean_slicing",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(z_min_clap, -1.04)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_max_clap, 9.06)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_min_snap, -2.77)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_max_snap, 1.05)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_min_high_five, -0.74)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_max_high_five, -0.32)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "check_slice": {
     "name": "check_slice",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rh_accelerometer_data.shape == (285, 3)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rh_accelerometer_data[0, 0], 0.7)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rh_accelerometer_data[0, -1], -0.41)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rh_accelerometer_data[-1, 0], 0.07)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rh_accelerometer_data[-1, -1], -0.98)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert lh_gyroscope_data.shape == (all_data.shape[0], 3)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(lh_gyroscope_data[0, 0], 429.34)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(lh_gyroscope_data[-1, -1], -154.36)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "get_data": {
     "name": "get_data",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_file_info('Data/S10F10.csv') == {'csv_path': 'Data/S10F10.csv', 'motion_id': high_five_id}\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_file_info('Data/S07S05.csv') == {'csv_path': 'Data/S07S05.csv', 'motion_id': snap_id}\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_file_info('Data/S03C09.csv') == {'csv_path': 'Data/S03C09.csv', 'motion_id': clap_id}\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all_data[0, -1] == clap_id\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all_data[102, -1] == high_five_id\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all_data[-1, -1] == snap_id\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all_data[0, 0] == 77093\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(all_data[0, -2], -311.4)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all_data[101, 0] == 27084\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(all_data[101, -2], -71.76)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(np.mean(all_data[:, 0]), 56082.1684, atol=0.001)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(np.mean(all_data[:, -1]), 1.95789, atol=0.001)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not 'not filled out' in worked_with_names\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not 'not filled out' in websites\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert hours > 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "loop_data_calc_stats": {
     "name": "loop_data_calc_stats",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(ret_stats_array) == 3\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert ret_stats_array[0]['Mean'] == 1.0\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert ret_stats_array[1]['Mean'] == 2.0\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert ret_stats_array[2]['Mean'] == 3.0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "optional_where": {
     "name": "optional_where",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert all_rows_with_min == [48]\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "stats_channel": {
     "name": "stats_channel",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(ret_dict['Min'], 0.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(ret_dict['Max'], 1.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(ret_dict['Mean'], 0.5)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(ret_dict['SD'], 0.319, atol=0.01)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
